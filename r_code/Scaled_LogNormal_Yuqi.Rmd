---
title: "Regression for Scaled Data"
author: "Yuqi Zhang"
date: "2024-06-10"
output: pdf_document
---

```{r}
scaled_data_train <- cbind(info_tr_train$ClaimNb_cap/info_tr_train$Exposure,info_tr_train)
colnames(scaled_data_train) <- c("Scaled_ClaimNb",colnames(info_tr_train))
scaled_data_train <- scaled_data_train[, -c(2,3,13)]

scaled_data_test <- cbind(info_tr_test$ClaimNb_cap/info_tr_test$Exposure,info_tr_test)
colnames(scaled_data_test) <- c("Scaled_ClaimNb",colnames(info_tr_test))
scaled_data_test <- scaled_data_test[, -c(2,3,13)]
```

```{r}
# log-transformation
scaled_data_train$log_Scaled_ClaimNb <- log(scaled_data_train$Scaled_ClaimNb + 1)
#scaled_data_train <- #scaled_data_train[scaled_data_train$Scaled_ClaimNb < quantile(scaled_data_train$Scaled_ClaimNb, 0.99),]

# Categorical to factors
scaled_data_train$Area <- as.factor(scaled_data_train$Area)
scaled_data_train$VehBrand <- as.factor(scaled_data_train$VehBrand)
scaled_data_train$VehGas <- as.factor(scaled_data_train$VehGas)
scaled_data_train$Region <- as.factor(scaled_data_train$Region)

scaled_data_train <- scaled_data_train[, -c(1)]

# log-transformation
scaled_data_test$log_Scaled_ClaimNb <- log(scaled_data_test$Scaled_ClaimNb + 1)
#scaled_data_test <- #scaled_data_test[scaled_data_test$Scaled_ClaimNb < quantile(scaled_data_test$Scaled_ClaimNb, 0.99),]

# Categorical to factors
scaled_data_test$Area <- as.factor(scaled_data_test$Area)
scaled_data_test$VehBrand <- as.factor(scaled_data_test$VehBrand)
scaled_data_test$VehGas <- as.factor(scaled_data_test$VehGas)
scaled_data_test$Region <- as.factor(scaled_data_test$Region)

scaled_data_test <- scaled_data_test[, -c(1)]
```


```{r}
library(nnet)
library(MASS)

# GLM
formula <- log_Scaled_ClaimNb ~as.factor(Area) + VehPower + VehAge + DrivAge + BonusMalus + as.factor(VehBrand) + as.factor(VehGas) + as.factor(Region) + Density

glm_model <- glm(formula, data = scaled_data_train, family = gaussian())
```



```{r}
library(caret)
library(xgboost)

X_train <- scaled_data_train[, -c(10)]
y_train <- scaled_data_train$log_Scaled_ClaimNb
X_test <- scaled_data_test[, -c(10)]
y_test <- scaled_data_test$log_Scaled_ClaimNb

categorical_features <- sapply(X_train, is.factor)
X_train[categorical_features] <- lapply(X_train[categorical_features], function(x) as.integer(as.factor(x)))

categorical_features <- sapply(X_test, is.factor)
X_test[categorical_features] <- lapply(X_test[categorical_features], function(x) as.integer(as.factor(x)))

X_train <- as.matrix(X_train)
X_test <- as.matrix(X_test)

# Converting to DMatrix for XGBoost
dtrain <- xgb.DMatrix(data = X_train, label = y_train)
dtest <- xgb.DMatrix(data = X_test, label = y_test)

```

```{r}
# XGBoost model parameters
params <- list(
  booster = "gbtree",
  objective = "reg:squaredlogerror",
  eta = 0.1,
  max_depth = 6,
  subsample = 0.5,
  colsample_bytree = 0.7
)

# XGBoost model
xgb_model <- xgboost(params = params, data = dtrain, nrounds = 100, verbose = 0)

```


```{r}
calculate_gini <- function(actual, predicted) {

  df <- data.frame(actual = actual, predicted = predicted)
  df <- df[order(df$predicted),]

  # Calculate the cumulative sums of actual values
  cum_actuals <- cumsum(df$actual) / sum(df$actual)
  cum_predicted = cumsum(df$predicted) / sum(df$predicted)
  
  # Area under the Lorenz curve
  Lorenz = cumsum(sort(df$actual) / sum(df$actual))
  B = sum(Lorenz[-length(Lorenz)]) / (length(Lorenz) - 1)

  # Area above the Lorenz curve
  A = 0.5 - B
  gini = (A / 0.5)

  return(gini)
}

```

```{r}
# GLM
predictions_glm <- exp(predict(glm_model, newdata = scaled_data_test, type = "response")) - 1

hist(predictions_glm)

# MSE for GLM
mse_glm <- mean((predictions_glm - info_tr_test$ClaimNb_cap/info_tr_test$Exposure)^2)
print(paste("GLM MSE:", mse_glm))

# Gini for GLM
gini_glm <- calculate_gini(info_tr_test$ClaimNb_cap/info_tr_test$Exposure, predictions_glm)
print(paste("GLM Gini:", gini_glm))

```

```{r}
# XGBoost
predictions_xgb <- predict(xgb_model, dtest)
predictions_xgb <- exp(predictions_xgb) - 1
hist(predictions_xgb)

# MSE for XGBoost
mse_xgb <- mean((predictions_xgb - info_tr_test$ClaimNb_cap/info_tr_test$Exposure)^2)
print(paste("XGBoost MSE:", mse_xgb))

# Gini for XGBoost
gini_xgb <- calculate_gini(info_tr_test$ClaimNb_cap/info_tr_test$Exposure, predictions_xgb)
print(paste("XGBoost Gini:", gini_xgb))

```
The very high Gini coefficients and show that GLM and XGBoost both effectively discriminate between different outcomes. It ranks the predictions very well relative to the actual data.


```{r}
# Reverse transformation log(Scaled_ClaimNb + 1)
predicted_scaled_claim_nb_glm <- exp(predictions_glm) - 1
predicted_scaled_claim_nb_xgb <- exp(predictions_xgb) - 1

hist(predicted_scaled_claim_nb_glm)
hist(predicted_scaled_claim_nb_xgb)

predicted_claimNb_glm <- predicted_scaled_claim_nb_glm * info_tr_test$Exposure
predicted_claimNb_xgb <- predicted_scaled_claim_nb_xgb * info_tr_test$Exposure

hist(predicted_claimNb_glm)
hist(predicted_claimNb_xgb)

```

```{r}
# Binary classification of predictions
binary_predictions_glm <- ifelse(predicted_claimNb_glm > 0.05, 1, 0)
binary_predictions_xgb <- ifelse(predicted_claimNb_xgb > 0.05, 1, 0)

# Actual binary values
binary_actuals <- ifelse(info_test$ClaimNb_cap > 0, 1, 0)

```

```{r}
length(binary_predictions_glm)
length(binary_predictions_xgb)
length(binary_actuals)
```

```{r}
library(caret)

# Confusion matrix for GLM
confusion_matrix_glm <- confusionMatrix(factor(binary_predictions_glm), factor(binary_actuals))
print(confusion_matrix_glm)

# Confusion matrix for XGBoost
confusion_matrix_xgb <- confusionMatrix(factor(binary_predictions_xgb), factor(binary_actuals))
print(confusion_matrix_xgb)

mean((binary_predictions_glm-binary_actuals)^2)
mean((binary_predictions_xgb-binary_actuals)^2)

calculate_gini(predicted_claimNb_glm, info_tr_test$ClaimNb_cap)
calculate_gini(predicted_claimNb_xgb, info_tr_test$ClaimNb_cap)
```


```{r}
min_length <- min(length(binary_predictions_glm), length(binary_predictions_xgb), length(binary_actuals))

data_for_plot <- data.frame(
  Actual = binary_actuals[1:min_length],
  GLM_Predictions = binary_predictions_glm[1:min_length],
  XGB_Predictions = binary_predictions_xgb[1:min_length]
)

library(reshape2)

melted_data <- melt(data_for_plot, id.vars = NULL, variable.name = "Model", value.name = "Claim Status")

```
```{r}
library(ggplot2)

ggplot(melted_data, aes(x = as.factor(`Claim Status`), fill = Model)) +
  geom_bar(position = "dodge", stat="count") +
  scale_x_discrete(labels = c("Zero", "Non-Zero")) + 
  labs(title = "Comparison of Actual and Predicted Claims (Binary)",
       x = "Claim Status",
       y = "Count",
       fill = "Model Type") +
  facet_wrap(~ Model, scales = "free_y") + 
  theme_minimal()


```


```{r}
prob_claimNb_xgb <- 1 - exp(-predicted_claimNb_xgb)
```




